\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{hastie}
\citation{Mitchell}
\citation{Wright1}
\citation{Boncz}
\citation{Kumar}
\citation{Wright}
\citation{CMU}
\citation{Boncz}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces GLMs and their functions.\relax }}{2}{table.caption.3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:glms}{{1}{2}{GLMs and their functions.\relax }{table.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}BACKGROUND AND PRELIMINARIES}{2}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Generalized Linear Models (GLMs)}{2}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Coordinate Descent(CD)}{2}{subsection.2.2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Coordinate Descent (CD)\relax }}{2}{algorithm.1}}
\newlabel{alg:cd}{{1}{2}{Coordinate Descent (CD)\relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}MonetDB}{2}{subsection.2.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Data Structure}{2}{subsubsection.2.3.1}}
\newlabel{BAT}{{1a}{3}{BAT Data Structure\relax }{figure.caption.4}{}}
\newlabel{sub@BAT}{{a}{3}{BAT Data Structure\relax }{figure.caption.4}{}}
\newlabel{logical mapping}{{1b}{3}{The logical mapping of BAT\relax }{figure.caption.4}{}}
\newlabel{sub@logical mapping}{{b}{3}{The logical mapping of BAT\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces MonetDB Data Structure\relax }}{3}{figure.caption.4}}
\newlabel{fig:ds}{{1}{3}{MonetDB Data Structure\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Examples of storage of relations in MonetDB\relax }}{3}{figure.caption.5}}
\newlabel{fig:relation}{{2}{3}{Examples of storage of relations in MonetDB\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Storing Relations in MonetDB}{3}{subsubsection.2.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Relational mapping of ``Order" table and ``Item" Table\relax }}{3}{figure.caption.6}}
\newlabel{fig:relation example}{{3}{3}{Relational mapping of ``Order" table and ``Item" Table\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Examples of relational mapping}{3}{subsubsection.2.3.3}}
\citation{cowbook}
\citation{datacube}
\citation{hastie}
\citation{hastie}
\citation{Kumar}
\citation{Shapiro}
\citation{Kumar}
\citation{Shapiro}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Notation for objects and parameters used in the cost models. I/O costs are counted in number of pages. Dividing by the disk throughput yields the estimated runtimes. NB: As a simplifying assumption, we use an 8B representation for all values: IDs, target, and features (categorical features are assumed be have been converted to numeric ones \cite  {hastie}). \relax }}{4}{table.caption.8}}
\newlabel{tab:symbol&meaning}{{2}{4}{Notation for objects and parameters used in the cost models. I/O costs are counted in number of pages. Dividing by the disk throughput yields the estimated runtimes. NB: As a simplifying assumption, we use an 8B representation for all values: IDs, target, and features (categorical features are assumed be have been converted to numeric ones \cite {hastie}). \relax }{table.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}SIMPLE APPROACHES}{4}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}CD After a Join: Materialize (M)}{4}{subsection.3.1}}
\newlabel{cost model}{{\caption@xref {cost model}{ on input line 322}}{4}{Assumptions and Cost Model}{table.caption.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Notation for the CPU cost model. The value of cost of funcG and funcF are specifically for LR.\relax }}{4}{table.caption.10}}
\newlabel{tab:symbol&meaning}{{3}{4}{Notation for the CPU cost model. The value of cost of funcG and funcF are specifically for LR.\relax }{table.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}CD Over a Join: Stream (S)}{4}{subsection.3.2}}
\citation{Kumar}
\citation{Kumar}
\citation{Kumar}
\citation{Kumar}
\@writefile{toc}{\contentsline {section}{\numberline {4}FACTORIZED LEARNING (FL)}{5}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Mechanism of FL in Column-Store with CD}{5}{subsection.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Complete logical workflow of factorized learning. Considering feature column $S_j$ in \textbf  {S}, simply calculate the partial gradient on corresponding column, and update the corresponding coordinate ($W_j$), and then update H. Considering feature column $R_j$ in \textbf  {R}, look up the KKMR (oid-oid mapping) both in computation of the partial gradient (mapping called ``RG") and update of the residual vector H (mapping called ``RH"). Here, $\gamma _{SUM}$ denotes a \texttt  {SUM} aggregation. \relax }}{6}{figure.caption.17}}
\newlabel{fig:fl}{{4}{6}{Complete logical workflow of factorized learning. Considering feature column $S_j$ in \textbf {S}, simply calculate the partial gradient on corresponding column, and update the corresponding coordinate ($W_j$), and then update H. Considering feature column $R_j$ in \textbf {R}, look up the KKMR (oid-oid mapping) both in computation of the partial gradient (mapping called ``RG") and update of the residual vector H (mapping called ``RH"). Here, $\gamma _{SUM}$ denotes a \texttt {SUM} aggregation. \relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Considering a dataset with only ten samples (then the size of corresponding \textbf  {S} is also ten), then the size of G is ten. Assume that the size of \textbf  {R} is three, and one feature in \textbf  {R} is \textbf  {RF}, then ``SG" for each entry RFj in \textbf  {RF} is the sum of corresponding entries in G that map to RFj. \relax }}{6}{figure.caption.18}}
\newlabel{fig:RG}{{5}{6}{Considering a dataset with only ten samples (then the size of corresponding \textbf {S} is also ten), then the size of G is ten. Assume that the size of \textbf {R} is three, and one feature in \textbf {R} is \textbf {RF}, then ``SG" for each entry RFj in \textbf {RF} is the sum of corresponding entries in G that map to RFj. \relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusions}{6}{section.5}}
\bibstyle{abbrv}
\bibdata{vldb_sample}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Considering a dataset with only ten samples (then the size of corresponding \textbf  {S} is also ten ), then the size of H is ten. Assume that the size of \textbf  {R} is three, and one feature in \textbf  {R} is \textbf  {RF}, then ``SH" for each entry RFj in \textbf  {RF} is the change of partial inner product on $X_{(,j)}$ that maps to RFj. \relax }}{7}{figure.caption.19}}
\newlabel{fig:RH}{{6}{7}{Considering a dataset with only ten samples (then the size of corresponding \textbf {S} is also ten ), then the size of H is ten. Assume that the size of \textbf {R} is three, and one feature in \textbf {R} is \textbf {RF}, then ``SH" for each entry RFj in \textbf {RF} is the change of partial inner product on $X_{(,j)}$ that maps to RFj. \relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Acknowledgments}{7}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}References}{7}{subsection.6.1}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Final Thoughts on Good Layout}{7}{appendix.A}}
